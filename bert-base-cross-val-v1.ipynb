{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-09-01T19:31:15.775372Z","iopub.status.busy":"2023-09-01T19:31:15.774962Z","iopub.status.idle":"2023-09-01T19:31:23.087762Z","shell.execute_reply":"2023-09-01T19:31:23.086455Z","shell.execute_reply.started":"2023-09-01T19:31:15.775337Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import torch\n","import gc\n","import torch.nn as nn\n","\n","from sklearn.model_selection import KFold, GroupKFold\n","from transformers import AutoModel, AutoTokenizer\n","from tqdm import tqdm\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:31:23.092317Z","iopub.status.busy":"2023-09-01T19:31:23.091009Z","iopub.status.idle":"2023-09-01T19:31:23.098796Z","shell.execute_reply":"2023-09-01T19:31:23.097237Z","shell.execute_reply.started":"2023-09-01T19:31:23.092265Z"},"trusted":true},"outputs":[],"source":["class config:\n","    learning_rate=1.5e-5\n","    weight_decay=0.02\n","    hidden_dropout_prob=0.005\n","    attention_probs_dropout_prob=0.005\n","    num_train_epochs=1\n","    n_splits=4\n","    batch_size=8\n","    random_seed=42\n","    save_steps=100\n","    max_length=512\n","    hidden_size = 512"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:31:23.102508Z","iopub.status.busy":"2023-09-01T19:31:23.100887Z","iopub.status.idle":"2023-09-01T19:31:23.248995Z","shell.execute_reply":"2023-09-01T19:31:23.247169Z","shell.execute_reply.started":"2023-09-01T19:31:23.102457Z"},"trusted":true},"outputs":[],"source":["# prompts = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/prompts_train.csv')\n","# train_data = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_train.csv')\n","\n","train_data = pd.read_csv('./Data/summaries_train.csv')"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:31:25.514243Z","iopub.status.busy":"2023-09-01T19:31:25.513458Z","iopub.status.idle":"2023-09-01T19:31:25.538050Z","shell.execute_reply":"2023-09-01T19:31:25.536693Z","shell.execute_reply.started":"2023-09-01T19:31:25.514201Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>student_id</th>\n","      <th>prompt_id</th>\n","      <th>text</th>\n","      <th>content</th>\n","      <th>wording</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000e8c3c7ddb</td>\n","      <td>814d6b</td>\n","      <td>The third wave was an experimentto see how peo...</td>\n","      <td>0.205683</td>\n","      <td>0.380538</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0020ae56ffbf</td>\n","      <td>ebad26</td>\n","      <td>They would rub it up with soda to make the sme...</td>\n","      <td>-0.548304</td>\n","      <td>0.506755</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>004e978e639e</td>\n","      <td>3b9047</td>\n","      <td>In Egypt, there were many occupations and soci...</td>\n","      <td>3.128928</td>\n","      <td>4.231226</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>005ab0199905</td>\n","      <td>3b9047</td>\n","      <td>The highest class was Pharaohs these people we...</td>\n","      <td>-0.210614</td>\n","      <td>-0.471415</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0070c9e7af47</td>\n","      <td>814d6b</td>\n","      <td>The Third Wave developed  rapidly because the ...</td>\n","      <td>3.272894</td>\n","      <td>3.219757</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     student_id prompt_id                                               text  \\\n","0  000e8c3c7ddb    814d6b  The third wave was an experimentto see how peo...   \n","1  0020ae56ffbf    ebad26  They would rub it up with soda to make the sme...   \n","2  004e978e639e    3b9047  In Egypt, there were many occupations and soci...   \n","3  005ab0199905    3b9047  The highest class was Pharaohs these people we...   \n","4  0070c9e7af47    814d6b  The Third Wave developed  rapidly because the ...   \n","\n","    content   wording  \n","0  0.205683  0.380538  \n","1 -0.548304  0.506755  \n","2  3.128928  4.231226  \n","3 -0.210614 -0.471415  \n","4  3.272894  3.219757  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["train_data.head()"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:32:25.416722Z","iopub.status.busy":"2023-09-01T19:32:25.415252Z","iopub.status.idle":"2023-09-01T19:32:25.449125Z","shell.execute_reply":"2023-09-01T19:32:25.447513Z","shell.execute_reply.started":"2023-09-01T19:32:25.416619Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>student_id</th>\n","      <th>prompt_id</th>\n","      <th>text</th>\n","      <th>content</th>\n","      <th>wording</th>\n","      <th>fold</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000e8c3c7ddb</td>\n","      <td>814d6b</td>\n","      <td>The third wave was an experimentto see how peo...</td>\n","      <td>0.205683</td>\n","      <td>0.380538</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0020ae56ffbf</td>\n","      <td>ebad26</td>\n","      <td>They would rub it up with soda to make the sme...</td>\n","      <td>-0.548304</td>\n","      <td>0.506755</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>004e978e639e</td>\n","      <td>3b9047</td>\n","      <td>In Egypt, there were many occupations and soci...</td>\n","      <td>3.128928</td>\n","      <td>4.231226</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>005ab0199905</td>\n","      <td>3b9047</td>\n","      <td>The highest class was Pharaohs these people we...</td>\n","      <td>-0.210614</td>\n","      <td>-0.471415</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0070c9e7af47</td>\n","      <td>814d6b</td>\n","      <td>The Third Wave developed  rapidly because the ...</td>\n","      <td>3.272894</td>\n","      <td>3.219757</td>\n","      <td>3.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     student_id prompt_id                                               text  \\\n","0  000e8c3c7ddb    814d6b  The third wave was an experimentto see how peo...   \n","1  0020ae56ffbf    ebad26  They would rub it up with soda to make the sme...   \n","2  004e978e639e    3b9047  In Egypt, there were many occupations and soci...   \n","3  005ab0199905    3b9047  The highest class was Pharaohs these people we...   \n","4  0070c9e7af47    814d6b  The Third Wave developed  rapidly because the ...   \n","\n","    content   wording  fold  \n","0  0.205683  0.380538   3.0  \n","1 -0.548304  0.506755   2.0  \n","2  3.128928  4.231226   1.0  \n","3 -0.210614 -0.471415   1.0  \n","4  3.272894  3.219757   3.0  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["gkf = GroupKFold(n_splits = config.n_splits)\n","\n","for i, (_, val_index) in enumerate(gkf.split(train_data, groups = train_data['prompt_id'])):\n","    train_data.loc[val_index, 'fold'] = i\n","    \n","train_data.head()"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T15:43:51.434732Z","iopub.status.busy":"2023-09-01T15:43:51.434467Z","iopub.status.idle":"2023-09-01T15:44:07.157833Z","shell.execute_reply":"2023-09-01T15:44:07.156696Z","shell.execute_reply.started":"2023-09-01T15:43:51.434697Z"},"trusted":true},"outputs":[],"source":["# tokenizer = AutoTokenizer.from_pretrained('/kaggle/input/hugging-face-models-safe-tensors/bert-base-uncased')\n","# bert_model = AutoModel.from_pretrained('/kaggle/input/hugging-face-models-safe-tensors/bert-base-uncased')\n","\n","tokenizer = AutoTokenizer.from_pretrained('./Models/bert-base-uncased')\n","bert_model = AutoModel.from_pretrained('./Models/bert-base-uncased')"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T15:44:07.159640Z","iopub.status.busy":"2023-09-01T15:44:07.159294Z","iopub.status.idle":"2023-09-01T15:44:07.168637Z","shell.execute_reply":"2023-09-01T15:44:07.167623Z","shell.execute_reply.started":"2023-09-01T15:44:07.159607Z"},"trusted":true},"outputs":[],"source":["class TorchDataConversion(torch.utils.data.Dataset):\n","    def __init__(self, encodings, label_contents, label_words):\n","        self.encodings = encodings\n","        self.label_contents = label_contents\n","        self.label_words = label_words\n","        \n","    def __getitem__(self, idx):\n","        input_ids = torch.tensor(self.encodings[\"input_ids\"][idx]).int()\n","        masks = torch.tensor(self.encodings[\"attention_mask\"][idx]).int()\n","        contents = torch.tensor([self.label_contents[idx]]).float()\n","        words = torch.tensor([self.label_words[idx]]).float()\n","        \n","        return {\n","            'input_ids': input_ids,\n","            'attention_mask': masks,\n","            'contents': contents,\n","            'words': words\n","        } \n","    \n","    def __len__(self):\n","        return len(self.label_contents)\n","        "]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T15:44:10.239299Z","iopub.status.busy":"2023-09-01T15:44:10.238625Z","iopub.status.idle":"2023-09-01T15:44:10.250202Z","shell.execute_reply":"2023-09-01T15:44:10.249299Z","shell.execute_reply.started":"2023-09-01T15:44:10.239264Z"},"trusted":true},"outputs":[],"source":["class MultiOutputBertModel(nn.Module):\n","    def __init__(self, bert_model, hidden_size):\n","        super(MultiOutputBertModel, self).__init__()\n","        self.bert = bert_model\n","        self.fc1 = nn.Linear(bert_model.config.hidden_size, hidden_size)\n","        self.relu = nn.ReLU()\n","        self.fc2_content = nn.Linear(hidden_size, 1)\n","        self.fc2_wording = nn.Linear(hidden_size, 1)\n","        \n","    def forward(self, input_ids, attention_mask):\n","        outputs = self.bert(input_ids, attention_mask = attention_mask)\n","        pooled_output = outputs.pooler_output\n","        x = self.fc1(pooled_output)\n","        x = self.relu(x)\n","        content_output = self.fc2_content(x)\n","        wording_output = self.fc2_wording(x)\n","        return content_output, wording_output"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# Cross Val metric\n","\n","def compute_mcrmse(eval_pred):\n","    \"\"\"\n","    Calculates mean columnwise root mean squared error\n","    https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/overview/evaluation\n","    \"\"\"\n","    preds, labels = eval_pred\n","\n","    col_rmse = np.sqrt(np.mean((preds - labels) ** 2, axis=0))\n","    mcrmse = np.mean(col_rmse)\n","\n","    return {\n","        \"content_rmse\": col_rmse[0],\n","        \"wording_rmse\": col_rmse[1],\n","        \"mcrmse\": mcrmse,\n","    }"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":["'test_eval_pred = np.random.rand(2,3,2)\\nscore = compute_mcrmse(test_eval_pred)\\nscore'"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# test dimensions of the mertic calc function\n","\"\"\"test_eval_pred = np.random.rand(2,3,2)\n","score = compute_mcrmse(test_eval_pred)\n","score\"\"\""]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T15:44:10.252283Z","iopub.status.busy":"2023-09-01T15:44:10.251656Z","iopub.status.idle":"2023-09-01T15:44:16.583109Z","shell.execute_reply":"2023-09-01T15:44:16.582041Z","shell.execute_reply.started":"2023-09-01T15:44:10.252251Z"},"trusted":true},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = MultiOutputBertModel(bert_model, config.hidden_size).to(device)\n","optimizer = torch.optim.AdamW(model.parameters(), lr = config.learning_rate)\n","criterion = nn.MSELoss().to(device)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold 0\n"]},{"name":"stderr","output_type":"stream","text":["                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/1] - Average Loss: 0.7970\n","Fold 0 Training complete!\n","Fold 0 eval results:\n","Content_rmse: 0.5203979151094575\n","Word_rmse: 0.08938121875986993\n","MCR_rmse: 0.5164702001854223\n","Fold 1\n"]},{"name":"stderr","output_type":"stream","text":["                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/1] - Average Loss: 0.4895\n","Fold 1 Training complete!\n","Fold 1 eval results:\n","Content_rmse: 1.469008323074167\n","Word_rmse: 0.4668046952272492\n","MCR_rmse: 0.4746719103736513\n","Fold 2\n"]},{"name":"stderr","output_type":"stream","text":["                                                                 \r"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/1] - Average Loss: 0.4350\n","Fold 2 Training complete!\n","Fold 2 eval results:\n","Content_rmse: 0.518462826239734\n","Word_rmse: 0.7259593304867207\n","MCR_rmse: 0.3490696404476706\n","Fold 3\n"]},{"name":"stderr","output_type":"stream","text":["                                                                 \r"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/1] - Average Loss: 0.3281\n","Fold 3 Training complete!\n","Fold 3 eval results:\n","Content_rmse: 0.4034974255968382\n","Word_rmse: 0.7360099567355907\n","MCR_rmse: 0.33246208620738915\n"]}],"source":["for fold in range(config.n_splits):\n","    print(f\"Fold {fold}\")\n","    # Split train and val dataset\n","    train_set = train_data[train_data[\"fold\"] != fold]\n","    val_set = train_data[train_data[\"fold\"] == fold]\n","\n","    train_encodings = tokenizer.batch_encode_plus(train_set['text'].to_list(), max_length = config.max_length, padding = 'max_length', truncation = True)\n","    train_dataset = TorchDataConversion(train_encodings, train_set['content'].ravel(), train_set['wording'].ravel())\n","    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = config.batch_size, shuffle = True)\n","\n","    val_encodings = tokenizer.batch_encode_plus(val_set['text'].to_list(), max_length = config.max_length, padding = 'max_length', truncation = True)\n","    val_dataset = TorchDataConversion(val_encodings, val_set['content'].ravel(), val_set['wording'].ravel())\n","    val_loader = torch.utils.data.DataLoader(val_dataset)\n","\n","    # Train model on train set\n","    for epoch in range(config.num_train_epochs):\n","        model.train()\n","        running_loss = 0.0\n","        with tqdm(train_loader, unit = \"batch\", leave = False) as t:\n","            for i, item in enumerate(t):\n","                batch_input_ids = item[\"input_ids\"].to(device)\n","                batch_att_mask = item[\"attention_mask\"].to(device)\n","                batch_content = item[\"contents\"].to(device)\n","                batch_wording = item[\"words\"].to(device)\n","                \n","                optimizer.zero_grad()\n","                content_pred, wording_pred = model(batch_input_ids, batch_att_mask)\n","                \n","                content_loss = criterion(content_pred.squeeze(), batch_content.squeeze())\n","                wording_loss = criterion(wording_pred.squeeze(), batch_wording.squeeze())\n","                \n","                loss = content_loss + wording_loss\n","                running_loss += loss.item()\n","                \n","                loss.backward()\n","                optimizer.step()\n","                \n","                t.set_postfix({\"loss\": loss.item()})\n","    \n","        average_loss = running_loss/len(train_loader)\n","        print(f\"Epoch [{epoch + 1}/{config.num_train_epochs}] - Average Loss: {average_loss:.4f}\")\n","    \n","    print(f\"Fold {fold} Training complete!\")\n","\n","    # Validate using validate set\n","    model.eval()\n","    val_loss = 0.0\n","    content_pred = []\n","    wording_pred = []\n","    content_true = []\n","    wording_true = []\n","\n","    with torch.no_grad():\n","        for i, item in enumerate(val_loader):\n","            input_ids = item[\"input_ids\"].to(device)\n","            att_mask = item[\"attention_mask\"].to(device)\n","            content_true.append(item[\"contents\"].cpu().item())\n","            wording_true.append(item[\"words\"].cpu().item())\n","\n","            content_pred_temp, wording_pred_temp = model(input_ids, att_mask)\n","            content_pred.append(content_pred_temp.cpu().item())\n","            wording_pred.append(wording_pred_temp.cpu().item())\n","\n","    eval_pred = [[content_pred, wording_pred],[content_true, wording_true]]\n","    eval_pred = np.array(eval_pred)\n","    eval_output = compute_mcrmse(eval_pred)\n","\n","    print(f\"Fold {fold} eval results:\")\n","    print(f\"Content_rmse: {eval_output['content_rmse']}\")\n","    print(f\"Word_rmse: {eval_output['wording_rmse']}\")\n","    print(f\"MCR_rmse: {eval_output['mcrmse']}\")\n","\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["# test_data = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_test.csv')\n","test_data = pd.read_csv('./Data/summaries_test.csv')"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>student_id</th>\n","      <th>prompt_id</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000000ffffff</td>\n","      <td>abc123</td>\n","      <td>Example text 1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>111111eeeeee</td>\n","      <td>def789</td>\n","      <td>Example text 2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>222222cccccc</td>\n","      <td>abc123</td>\n","      <td>Example text 3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>333333dddddd</td>\n","      <td>def789</td>\n","      <td>Example text 4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     student_id prompt_id            text\n","0  000000ffffff    abc123  Example text 1\n","1  111111eeeeee    def789  Example text 2\n","2  222222cccccc    abc123  Example text 3\n","3  333333dddddd    def789  Example text 4"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["test_data.head()"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["class TorchDataConversion_test(torch.utils.data.Dataset):\n","    def __init__(self, encodings):\n","        self.encodings = encodings\n","        \n","    def __getitem__(self, idx):\n","        input_ids = torch.tensor(self.encodings[\"input_ids\"][idx]).int()\n","        masks = torch.tensor(self.encodings[\"attention_mask\"][idx]).int()\n","        \n","        return {\n","            'input_ids': input_ids,\n","            'attention_mask': masks,\n","        } \n","    \n","    def __len__(self):\n","        return len(self.encodings['input_ids'])  "]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["test_encodings = tokenizer.batch_encode_plus(test_data['text'].to_list(), max_length = config.max_length, padding = 'max_length', truncation = True)\n","test_dataset = TorchDataConversion_test(test_encodings)\n","test_loader = torch.utils.data.DataLoader(test_dataset)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["model.eval()\n","content_score = []\n","wording_score = []\n","with torch.no_grad():\n","    for i, item in enumerate(test_loader):\n","        input_ids = item[\"input_ids\"].to(device)\n","        att_mask = item[\"attention_mask\"].to(device)\n","        \n","        content_pred, wording_pred = model(input_ids, att_mask)\n","        content_score.append(content_pred.cpu().item())\n","        wording_score.append(wording_pred.cpu().item())"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["submission_df = pd.DataFrame({\n","    'student_id': test_data['student_id'],\n","    'content': content_score,\n","    'wording': wording_score\n","})\n","\n","submission_df.to_csv('submission.csv', index= False)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>student_id</th>\n","      <th>content</th>\n","      <th>wording</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000000ffffff</td>\n","      <td>-1.272173</td>\n","      <td>-1.226621</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>111111eeeeee</td>\n","      <td>-1.276924</td>\n","      <td>-1.224973</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>222222cccccc</td>\n","      <td>-1.273461</td>\n","      <td>-1.223927</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>333333dddddd</td>\n","      <td>-1.282219</td>\n","      <td>-1.236035</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     student_id   content   wording\n","0  000000ffffff -1.272173 -1.226621\n","1  111111eeeeee -1.276924 -1.224973\n","2  222222cccccc -1.273461 -1.223927\n","3  333333dddddd -1.282219 -1.236035"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["submission_df.head()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":4}
