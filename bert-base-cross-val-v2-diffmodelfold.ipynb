{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-09-01T19:31:15.775372Z","iopub.status.busy":"2023-09-01T19:31:15.774962Z","iopub.status.idle":"2023-09-01T19:31:23.087762Z","shell.execute_reply":"2023-09-01T19:31:23.086455Z","shell.execute_reply.started":"2023-09-01T19:31:15.775337Z"},"trusted":true},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'transformers'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m KFold, GroupKFold\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m mean_squared_error\n\u001b[0;32m---> 13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoModel, AutoTokenizer\n\u001b[1;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import torch\n","import gc\n","import torch.nn as nn\n","\n","from sklearn.model_selection import KFold, GroupKFold\n","from sklearn.metrics import mean_squared_error\n","from transformers import AutoModel, AutoTokenizer\n","from tqdm import tqdm\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:31:23.092317Z","iopub.status.busy":"2023-09-01T19:31:23.091009Z","iopub.status.idle":"2023-09-01T19:31:23.098796Z","shell.execute_reply":"2023-09-01T19:31:23.097237Z","shell.execute_reply.started":"2023-09-01T19:31:23.092265Z"},"trusted":true},"outputs":[],"source":["class config:\n","    learning_rate=1.5e-5\n","    weight_decay=0.02\n","    hidden_dropout_prob=0.005\n","    attention_probs_dropout_prob=0.005\n","    num_train_epochs=1\n","    n_splits=4\n","    batch_size=8\n","    random_seed=42\n","    save_steps=100\n","    max_length=512\n","    hidden_size = 512"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:31:23.102508Z","iopub.status.busy":"2023-09-01T19:31:23.100887Z","iopub.status.idle":"2023-09-01T19:31:23.248995Z","shell.execute_reply":"2023-09-01T19:31:23.247169Z","shell.execute_reply.started":"2023-09-01T19:31:23.102457Z"},"trusted":true},"outputs":[],"source":["# prompts = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/prompts_train.csv')\n","# train_data = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_train.csv')\n","\n","train_data = pd.read_csv('./Data/summaries_train.csv')"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:31:25.514243Z","iopub.status.busy":"2023-09-01T19:31:25.513458Z","iopub.status.idle":"2023-09-01T19:31:25.538050Z","shell.execute_reply":"2023-09-01T19:31:25.536693Z","shell.execute_reply.started":"2023-09-01T19:31:25.514201Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>student_id</th>\n","      <th>prompt_id</th>\n","      <th>text</th>\n","      <th>content</th>\n","      <th>wording</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000e8c3c7ddb</td>\n","      <td>814d6b</td>\n","      <td>The third wave was an experimentto see how peo...</td>\n","      <td>0.205683</td>\n","      <td>0.380538</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0020ae56ffbf</td>\n","      <td>ebad26</td>\n","      <td>They would rub it up with soda to make the sme...</td>\n","      <td>-0.548304</td>\n","      <td>0.506755</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>004e978e639e</td>\n","      <td>3b9047</td>\n","      <td>In Egypt, there were many occupations and soci...</td>\n","      <td>3.128928</td>\n","      <td>4.231226</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>005ab0199905</td>\n","      <td>3b9047</td>\n","      <td>The highest class was Pharaohs these people we...</td>\n","      <td>-0.210614</td>\n","      <td>-0.471415</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0070c9e7af47</td>\n","      <td>814d6b</td>\n","      <td>The Third Wave developed  rapidly because the ...</td>\n","      <td>3.272894</td>\n","      <td>3.219757</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     student_id prompt_id                                               text  \\\n","0  000e8c3c7ddb    814d6b  The third wave was an experimentto see how peo...   \n","1  0020ae56ffbf    ebad26  They would rub it up with soda to make the sme...   \n","2  004e978e639e    3b9047  In Egypt, there were many occupations and soci...   \n","3  005ab0199905    3b9047  The highest class was Pharaohs these people we...   \n","4  0070c9e7af47    814d6b  The Third Wave developed  rapidly because the ...   \n","\n","    content   wording  \n","0  0.205683  0.380538  \n","1 -0.548304  0.506755  \n","2  3.128928  4.231226  \n","3 -0.210614 -0.471415  \n","4  3.272894  3.219757  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["train_data.head()"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T19:32:25.416722Z","iopub.status.busy":"2023-09-01T19:32:25.415252Z","iopub.status.idle":"2023-09-01T19:32:25.449125Z","shell.execute_reply":"2023-09-01T19:32:25.447513Z","shell.execute_reply.started":"2023-09-01T19:32:25.416619Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>student_id</th>\n","      <th>prompt_id</th>\n","      <th>text</th>\n","      <th>content</th>\n","      <th>wording</th>\n","      <th>fold</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000e8c3c7ddb</td>\n","      <td>814d6b</td>\n","      <td>The third wave was an experimentto see how peo...</td>\n","      <td>0.205683</td>\n","      <td>0.380538</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0020ae56ffbf</td>\n","      <td>ebad26</td>\n","      <td>They would rub it up with soda to make the sme...</td>\n","      <td>-0.548304</td>\n","      <td>0.506755</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>004e978e639e</td>\n","      <td>3b9047</td>\n","      <td>In Egypt, there were many occupations and soci...</td>\n","      <td>3.128928</td>\n","      <td>4.231226</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>005ab0199905</td>\n","      <td>3b9047</td>\n","      <td>The highest class was Pharaohs these people we...</td>\n","      <td>-0.210614</td>\n","      <td>-0.471415</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0070c9e7af47</td>\n","      <td>814d6b</td>\n","      <td>The Third Wave developed  rapidly because the ...</td>\n","      <td>3.272894</td>\n","      <td>3.219757</td>\n","      <td>3.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     student_id prompt_id                                               text  \\\n","0  000e8c3c7ddb    814d6b  The third wave was an experimentto see how peo...   \n","1  0020ae56ffbf    ebad26  They would rub it up with soda to make the sme...   \n","2  004e978e639e    3b9047  In Egypt, there were many occupations and soci...   \n","3  005ab0199905    3b9047  The highest class was Pharaohs these people we...   \n","4  0070c9e7af47    814d6b  The Third Wave developed  rapidly because the ...   \n","\n","    content   wording  fold  \n","0  0.205683  0.380538   3.0  \n","1 -0.548304  0.506755   2.0  \n","2  3.128928  4.231226   1.0  \n","3 -0.210614 -0.471415   1.0  \n","4  3.272894  3.219757   3.0  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["gkf = GroupKFold(n_splits = config.n_splits)\n","\n","for i, (_, val_index) in enumerate(gkf.split(train_data, groups = train_data['prompt_id'])):\n","    train_data.loc[val_index, 'fold'] = i\n","    \n","train_data.head()"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T15:44:07.159640Z","iopub.status.busy":"2023-09-01T15:44:07.159294Z","iopub.status.idle":"2023-09-01T15:44:07.168637Z","shell.execute_reply":"2023-09-01T15:44:07.167623Z","shell.execute_reply.started":"2023-09-01T15:44:07.159607Z"},"trusted":true},"outputs":[],"source":["class TorchDataConversion(torch.utils.data.Dataset):\n","    def __init__(self, encodings, label_contents, label_words):\n","        self.encodings = encodings\n","        self.label_contents = label_contents\n","        self.label_words = label_words\n","        \n","    def __getitem__(self, idx):\n","        input_ids = torch.tensor(self.encodings[\"input_ids\"][idx]).int()\n","        masks = torch.tensor(self.encodings[\"attention_mask\"][idx]).int()\n","        contents = torch.tensor([self.label_contents[idx]]).float()\n","        words = torch.tensor([self.label_words[idx]]).float()\n","        \n","        return {\n","            'input_ids': input_ids,\n","            'attention_mask': masks,\n","            'contents': contents,\n","            'words': words\n","        } \n","    \n","    def __len__(self):\n","        return len(self.label_contents)\n","        "]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T15:44:10.239299Z","iopub.status.busy":"2023-09-01T15:44:10.238625Z","iopub.status.idle":"2023-09-01T15:44:10.250202Z","shell.execute_reply":"2023-09-01T15:44:10.249299Z","shell.execute_reply.started":"2023-09-01T15:44:10.239264Z"},"trusted":true},"outputs":[],"source":["class MultiOutputBertModel(nn.Module):\n","    def __init__(self, hidden_size):\n","        super(MultiOutputBertModel, self).__init__()\n","        self.bert = AutoModel.from_pretrained('./Models/bert-base-uncased')\n","        self.fc1 = nn.Linear(self.bert.config.hidden_size, hidden_size)\n","        self.relu = nn.ReLU()\n","        self.fc2_content = nn.Linear(hidden_size, 1)\n","        self.fc2_wording = nn.Linear(hidden_size, 1)\n","        # tokenizer = AutoTokenizer.from_pretrained('/kaggle/input/hugging-face-models-safe-tensors/bert-base-uncased')\n","        # bert_model = AutoModel.from_pretrained('/kaggle/input/hugging-face-models-safe-tensors/bert-base-uncased')\n","        \n","    def forward(self, input_ids, attention_mask):\n","        outputs = self.bert(input_ids, attention_mask = attention_mask)\n","        pooled_output = outputs.pooler_output\n","        x = self.fc1(pooled_output)\n","        x = self.relu(x)\n","        content_output = self.fc2_content(x)\n","        wording_output = self.fc2_wording(x)\n","        return content_output, wording_output"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# Cross Val metric\n","\"\"\"\n","def compute_mcrmse(eval_pred):\n","   \n","    # Calculates mean columnwise root mean squared error\n","    # https://www.kaggle.com/competitions/commonlit-evaluate-student-summaries/overview/evaluation\n","    preds, labels = eval_pred\n","\n","    col_rmse = np.sqrt(np.mean((preds - labels) ** 2, axis=0))\n","    mcrmse = np.mean(col_rmse)\n","\n","    return {\n","        \"content_rmse\": col_rmse[0],\n","        \"wording_rmse\": col_rmse[1],\n","        \"mcrmse\": mcrmse,\n","    } \"\"\"\n","\n","\n","def compute_mcrmse(y_trues, y_preds):\n","    scores = []\n","    idxes = y_trues.shape[1]\n","    for i in range(idxes):\n","        y_true = y_trues[:,i]#.detach().to('cpu').numpy()\n","        y_pred = y_preds[:,i]#.detach().to('cpu').numpy()\n","        score = mean_squared_error(y_true, y_pred, squared=False) # RMSE\n","        scores.append(score)\n","    mcrmse_score = np.mean(scores)\n","    return mcrmse_score, scores\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["'test_eval_pred = np.random.rand(2,3,2)\\nscore = compute_mcrmse(test_eval_pred)\\nscore'"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# test dimensions of the mertic calc function\n","\"\"\"test_eval_pred = np.random.rand(2,3,2)\n","score = compute_mcrmse(test_eval_pred)\n","score\"\"\""]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-09-01T15:44:10.252283Z","iopub.status.busy":"2023-09-01T15:44:10.251656Z","iopub.status.idle":"2023-09-01T15:44:16.583109Z","shell.execute_reply":"2023-09-01T15:44:16.582041Z","shell.execute_reply.started":"2023-09-01T15:44:10.252251Z"},"trusted":true},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","tokenizer = AutoTokenizer.from_pretrained('./Models/bert-base-uncased')\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold 0\n"]},{"name":"stderr","output_type":"stream","text":["                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/1] - Average Loss: 0.8549\n","Fold 0 Training complete!\n","Validation loss: 0.6309473893069957\n","Fold 0 eval results:\n","Content_rmse: 0.3648337004741352\n","Word_rmse: 0.5079101855563489\n","MCR_rmse: 0.43637194301524207\n","Model_fold0 saved!\n","Fold 1\n"]},{"name":"stderr","output_type":"stream","text":["                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/1] - Average Loss: 0.6806\n","Fold 1 Training complete!\n","Validation loss: 1.1138032601598455\n","Fold 1 eval results:\n","Content_rmse: 0.420893466259103\n","Word_rmse: 0.6514707212442984\n","MCR_rmse: 0.5361820937517007\n","Model_fold1 saved!\n","Fold 2\n"]},{"name":"stderr","output_type":"stream","text":["                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/1] - Average Loss: 0.8239\n","Fold 2 Training complete!\n","Validation loss: 0.821220813301207\n","Fold 2 eval results:\n","Content_rmse: 0.4265400809137886\n","Word_rmse: 0.5357827372242532\n","MCR_rmse: 0.4811614090690209\n","Model_fold2 saved!\n","Fold 3\n"]},{"name":"stderr","output_type":"stream","text":["                                                                \r"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/1] - Average Loss: 0.7333\n","Fold 3 Training complete!\n","Validation loss: 1.0698516234920799\n","Fold 3 eval results:\n","Content_rmse: 0.5092548839139971\n","Word_rmse: 0.6352998464022521\n","MCR_rmse: 0.5722773651581246\n","Model_fold3 saved!\n"]}],"source":["for fold in range(config.n_splits):\n","    print(f\"Fold {fold}\")\n","    # Split train and val dataset\n","    train_set = train_data[train_data[\"fold\"] != fold]\n","    val_set = train_data[train_data[\"fold\"] == fold]\n","\n","    train_encodings = tokenizer.batch_encode_plus(train_set['text'].to_list(), max_length = config.max_length, padding = 'max_length', truncation = True)\n","    train_dataset = TorchDataConversion(train_encodings, train_set['content'].ravel(), train_set['wording'].ravel())\n","    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = config.batch_size, shuffle = True)\n","\n","    val_encodings = tokenizer.batch_encode_plus(val_set['text'].to_list(), max_length = config.max_length, padding = 'max_length', truncation = True)\n","    val_dataset = TorchDataConversion(val_encodings, val_set['content'].ravel(), val_set['wording'].ravel())\n","    val_loader = torch.utils.data.DataLoader(val_dataset)\n","\n","    model = MultiOutputBertModel(config.hidden_size).to(device)\n","    optimizer = torch.optim.AdamW(model.parameters(), lr = config.learning_rate)\n","    criterion = nn.MSELoss().to(device) \n","    \n","    # Train model on train set\n","    for epoch in range(config.num_train_epochs):\n","        model.train()\n","        running_loss = 0.0\n","        with tqdm(train_loader, unit = \"batch\", leave = False) as t:\n","            for i, item in enumerate(t):\n","                batch_input_ids = item[\"input_ids\"].to(device)\n","                batch_att_mask = item[\"attention_mask\"].to(device)\n","                batch_content = item[\"contents\"].to(device)\n","                batch_wording = item[\"words\"].to(device)\n","                \n","                optimizer.zero_grad()\n","                content_pred, wording_pred = model(batch_input_ids, batch_att_mask)\n","                \n","                content_loss = criterion(content_pred.squeeze(), batch_content.squeeze())\n","                wording_loss = criterion(wording_pred.squeeze(), batch_wording.squeeze())\n","                \n","                loss = content_loss + wording_loss\n","                running_loss += loss.item()\n","                \n","                loss.backward()\n","                optimizer.step()\n","                \n","                t.set_postfix({\"loss\": loss.item()})\n","    \n","        average_loss = running_loss/len(train_loader)\n","        print(f\"Epoch [{epoch + 1}/{config.num_train_epochs}] - Average Loss: {average_loss:.4f}\")\n","    \n","    print(f\"Fold {fold} Training complete!\")\n","\n","    # Validate using validate set\n","    model.eval()\n","    val_loss = 0.0\n","    content_pred = []\n","    wording_pred = []\n","    content_true = []\n","    wording_true = []\n","\n","    with torch.no_grad():\n","        for i, item in enumerate(val_loader):\n","            input_ids = item[\"input_ids\"].to(device)\n","            att_mask = item[\"attention_mask\"].to(device)\n","            content_true.append(item[\"contents\"].cpu().item())\n","            wording_true.append(item[\"words\"].cpu().item())\n","\n","            content_pred_temp, wording_pred_temp = model(input_ids, att_mask)\n","            content_pred.append(content_pred_temp.cpu().item())\n","            wording_pred.append(wording_pred_temp.cpu().item())\n","\n","            content_loss = criterion(content_pred_temp, item[\"contents\"].to(device))\n","            wording_loss = criterion(wording_pred_temp, item[\"words\"].to(device))\n","                \n","            loss = content_loss + wording_loss\n","            val_loss += loss.item()\n","\n","        average_val_loss = val_loss/len(val_loader)\n","        print(f\"Validation loss: {average_val_loss}\")\n","\n","    eval_pred = [[content_pred, wording_pred]]\n","    eval_pred = np.array(eval_pred)\n","    eval_true = [[content_true, wording_true]]\n","    eval_true = np.array(eval_true)\n","    eval_mcrmse_score, eval_scores = compute_mcrmse(eval_true, eval_pred)\n","\n","    \"\"\"print(f\"Fold {fold} eval results:\")\n","    print(f\"Content_rmse: {eval_output['content_rmse']}\")\n","    print(f\"Word_rmse: {eval_output['wording_rmse']}\")\n","    print(f\"MCR_rmse: {eval_output['mcrmse']}\")\"\"\"\n","\n","    print(f\"Fold {fold} eval results:\")\n","    print(f\"Content_rmse: {eval_scores[0]}\")\n","    print(f\"Word_rmse: {eval_scores[1]}\")\n","    print(f\"MCR_rmse: {eval_mcrmse_score}\")\n","    # Save the model for this round\n","    torch.save(model.state_dict(), f'./bert-base-uncased/model_fold{fold}.pth')\n","    print(f'Model_fold{fold} saved!')\n","\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# test_data = pd.read_csv('/kaggle/input/commonlit-evaluate-student-summaries/summaries_test.csv')\n","test_data = pd.read_csv('./Data/summaries_test.csv')"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>student_id</th>\n","      <th>prompt_id</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000000ffffff</td>\n","      <td>abc123</td>\n","      <td>Example text 1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>111111eeeeee</td>\n","      <td>def789</td>\n","      <td>Example text 2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>222222cccccc</td>\n","      <td>abc123</td>\n","      <td>Example text 3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>333333dddddd</td>\n","      <td>def789</td>\n","      <td>Example text 4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     student_id prompt_id            text\n","0  000000ffffff    abc123  Example text 1\n","1  111111eeeeee    def789  Example text 2\n","2  222222cccccc    abc123  Example text 3\n","3  333333dddddd    def789  Example text 4"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["test_data.head()"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["class TorchDataConversion_test(torch.utils.data.Dataset):\n","    def __init__(self, encodings):\n","        self.encodings = encodings\n","        \n","    def __getitem__(self, idx):\n","        input_ids = torch.tensor(self.encodings[\"input_ids\"][idx]).int()\n","        masks = torch.tensor(self.encodings[\"attention_mask\"][idx]).int()\n","        \n","        return {\n","            'input_ids': input_ids,\n","            'attention_mask': masks,\n","        } \n","    \n","    def __len__(self):\n","        return len(self.encodings['input_ids'])  "]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["test_encodings = tokenizer.batch_encode_plus(test_data['text'].to_list(), max_length = config.max_length, padding = 'max_length', truncation = True)\n","test_dataset = TorchDataConversion_test(test_encodings)\n","test_loader = torch.utils.data.DataLoader(test_dataset)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["model.eval()\n","content_score = []\n","wording_score = []\n","with torch.no_grad():\n","    for i, item in enumerate(test_loader):\n","        input_ids = item[\"input_ids\"].to(device)\n","        att_mask = item[\"attention_mask\"].to(device)\n","        \n","        content_pred, wording_pred = model(input_ids, att_mask)\n","        content_score.append(content_pred.cpu().item())\n","        wording_score.append(wording_pred.cpu().item())"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["submission_df = pd.DataFrame({\n","    'student_id': test_data['student_id'],\n","    'content': content_score,\n","    'wording': wording_score\n","})\n","\n","submission_df.to_csv('submission.csv', index= False)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>student_id</th>\n","      <th>content</th>\n","      <th>wording</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>000000ffffff</td>\n","      <td>-0.954275</td>\n","      <td>-0.826337</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>111111eeeeee</td>\n","      <td>-1.003406</td>\n","      <td>-0.861793</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>222222cccccc</td>\n","      <td>-1.008330</td>\n","      <td>-0.874556</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>333333dddddd</td>\n","      <td>-1.007877</td>\n","      <td>-0.874800</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     student_id   content   wording\n","0  000000ffffff -0.954275 -0.826337\n","1  111111eeeeee -1.003406 -0.861793\n","2  222222cccccc -1.008330 -0.874556\n","3  333333dddddd -1.007877 -0.874800"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["submission_df.head()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":4}
